{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchinfo\n",
    "import onnx\n",
    "import torch.onnx\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import struct\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, init_weights=True):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=4, stride=2, bias=False)\n",
    "        # self.conv2 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=4, stride=2)\n",
    "        # self.conv3 = nn.Conv2d(in_channels=5, out_channels=5, kernel_size=4, stride=2)\n",
    "\n",
    "        # self.linear1 = nn.Linear(in_features=3 * 15 * 15, out_features=10)\n",
    "        # self.linear1 = nn.Linear(in_features=5 * 2 * 2, out_features=10)\n",
    "        # self.linear2 = nn.Linear(in_features=10, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        # x = F.relu(x)\n",
    "        # x = self.conv2(x)\n",
    "        # x = F.relu(x)\n",
    "        # x = self.conv3(x)\n",
    "        # x = F.relu(x)\n",
    "        # x = torch.flatten(x, start_dim=1)\n",
    "        # x = self.linear1(x)\n",
    "        # x = F.relu(x)\n",
    "        # x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "# class MNISTloader:\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         batch_size: int = 64,\n",
    "#         data_dir: str = \"./data/\",\n",
    "#         num_workers: int = 0,\n",
    "#         pin_memory: bool = False,\n",
    "#         shuffle: bool = False,\n",
    "#         train_val_split: float = 0.1,\n",
    "#     ):\n",
    "#         self.batch_size = batch_size\n",
    "#         self.data_dir = data_dir\n",
    "#         self.num_workers = num_workers\n",
    "#         self.pin_memory = pin_memory\n",
    "#         self.shuffle = shuffle\n",
    "#         self.train_val_split = train_val_split\n",
    "\n",
    "#         self.setup()\n",
    "\n",
    "#     def setup(self):\n",
    "#         transform = transforms.Compose(\n",
    "#             [\n",
    "#                 transforms.Resize((32, 32)),\n",
    "#                 transforms.ToTensor(),\n",
    "#                 transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "#             ]\n",
    "#         )\n",
    "\n",
    "#         self.train_dataset = datasets.MNIST(\n",
    "#             self.data_dir, train=True, download=True, transform=transform\n",
    "#         )\n",
    "#         val_split = int(len(self.train_dataset) * self.train_val_split)\n",
    "#         train_split = len(self.train_dataset) - val_split\n",
    "\n",
    "#         self.train_dataset, self.val_dataset = random_split(\n",
    "#             self.train_dataset, [train_split, val_split]\n",
    "#         )\n",
    "#         self.test_dataset = datasets.MNIST(\n",
    "#             self.data_dir, train=False, download=True, transform=transform\n",
    "#         )\n",
    "\n",
    "#         print(\n",
    "#             \"Image Shape:    {}\".format(self.train_dataset[0][0].numpy().shape),\n",
    "#             end=\"\\n\\n\",\n",
    "#         )\n",
    "#         print(\"Training Set:   {} samples\".format(len(self.train_dataset)))\n",
    "#         print(\"Validation Set: {} samples\".format(len(self.val_dataset)))\n",
    "#         print(\"Test Set:       {} samples\".format(len(self.test_dataset)))\n",
    "\n",
    "#     def load(self):\n",
    "#         train_loader = DataLoader(\n",
    "#             dataset=self.train_dataset,\n",
    "#             batch_size=self.batch_size,\n",
    "#             num_workers=self.num_workers,\n",
    "#             pin_memory=self.pin_memory,\n",
    "#             shuffle=self.shuffle,\n",
    "#         )\n",
    "\n",
    "#         val_loader = DataLoader(\n",
    "#             dataset=self.val_dataset,\n",
    "#             batch_size=self.batch_size,\n",
    "#             num_workers=self.num_workers,\n",
    "#             pin_memory=self.pin_memory,\n",
    "#             shuffle=self.shuffle,\n",
    "#         )\n",
    "\n",
    "#         test_loader = DataLoader(\n",
    "#             dataset=self.test_dataset,\n",
    "#             batch_size=self.batch_size,\n",
    "#             num_workers=self.num_workers,\n",
    "#             pin_memory=self.pin_memory,\n",
    "#             shuffle=self.shuffle,\n",
    "#         )\n",
    "\n",
    "#         return train_loader, val_loader, test_loader\n",
    "\n",
    "# def train(device, lr, model, optimizer, criterion, train_loader):\n",
    "\n",
    "#     train_loss_running, train_acc_running = 0, 0\n",
    "\n",
    "#     model.train().cuda() if torch.cuda.is_available() else model.train()\n",
    "\n",
    "#     for inputs, labels in train_loader:\n",
    "\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         outputs = model(inputs)\n",
    "\n",
    "#         _, predictions = torch.max(outputs, dim=1)\n",
    "#         loss = criterion(outputs, labels)\n",
    "        \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         train_loss_running += loss.item() * inputs.shape[0]\n",
    "#         train_acc_running += torch.sum(predictions == labels.data)\n",
    "\n",
    "#     train_loss = train_loss_running / len(train_loader.sampler)\n",
    "#     train_acc = train_acc_running / len(train_loader.sampler)\n",
    "    \n",
    "#     return train_loss, train_acc\n",
    "    \n",
    "# def evaluate(device, model, criterion, val_loader):\n",
    "\n",
    "#     val_loss_running, val_acc_running = 0, 0\n",
    "    \n",
    "#     model.eval().cuda() if torch.cuda.is_available() else model.eval()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in val_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             _, predictions = torch.max(outputs, dim=1)\n",
    "#             val_loss_running += loss.item() * inputs.shape[0]\n",
    "#             val_acc_running += torch.sum(predictions == labels.data)\n",
    "\n",
    "#         val_loss = val_loss_running / len(val_loader.sampler)\n",
    "#         val_acc = val_acc_running / len(val_loader.sampler)\n",
    "\n",
    "#     return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader, val_loader, test_loader = MNISTloader(train_val_split=0.1).load()\n",
    "# model = SimpleNet()\n",
    "# torchinfo.summary(model, input_size=(16, 1, 32, 32))\n",
    "\n",
    "# lr = 0.001\n",
    "# num_epochs = 1\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = model.to(device)\n",
    "# optimizer = optim.Adam(model.parameters(), lr)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_loss, train_acc = train(device, lr, model, optimizer, criterion, train_loader)\n",
    "#     val_loss, val_acc = evaluate(device, model, criterion, val_loader)\n",
    "#     info = \"Epoch: {:3}/{} \\t train_Loss: {:.3f} \\t train_acc: {:.3f} \\t val_loss: {:.3f} \\t val_acc: {:.3f}\"\n",
    "#     print(info.format(epoch + 1, num_epochs, train_loss, train_acc, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(device, model, criterion, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.nn.Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(0, 0), dilation=(1, 1), bias=True)\n",
    "model = SimpleNet()\n",
    "model = model.cuda() if torch.cuda.is_available() else model.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randn(1, 2, 5, 5, requires_grad=True)\n",
    "x = torch.randn(1, 1, 4, 4, requires_grad=True)\n",
    "x = x.cuda() if torch.cuda.is_available() else x.cpu()\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(model,                     # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"conv2d_bias.onnx\",              # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=13,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is valid!\n"
     ]
    }
   ],
   "source": [
    "def onnx_check_model(onnx_model):\n",
    "    try:\n",
    "        onnx.checker.check_model(onnx_model)\n",
    "    except onnx.checker.ValidationError as e:\n",
    "        print('The model is invalid: %s' % e)\n",
    "    else:\n",
    "        print('The model is valid!')\n",
    "\n",
    "model_onnx = onnx.load(\"conv2d_bias.onnx\")\n",
    "onnx_check_model(model_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from converter.converter import parse_onnx_model, dump_onnx_model\n",
    "from converter.helpers import TYPEDEF\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "ir = parse_onnx_model(model_onnx)\n",
    "# dump_onnx_model(ir, \"ir.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for idx, layer in ir.items():\n",
    "    if (idx == 1):\n",
    "        print(len(layer[\"initializer\"]))\n",
    "        print((layer[\"initializer\"][\"weight\"] != {}) + (layer[\"initializer\"][\"bias\"] != {}))\n",
    "        print(layer[\"initializer\"][\"bias\"] == {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(0,\n",
       "              {'name': 'input',\n",
       "               'op_type': INPUT,\n",
       "               'inputs': [],\n",
       "               'outputs': [1],\n",
       "               'dims': [1, 1, 4, 4]}),\n",
       "             (1,\n",
       "              {'name': 'Conv_0',\n",
       "               'op_type': CONV2D,\n",
       "               'initializer': {'weight': {'name': 'conv1.weight',\n",
       "                 'raw_data': b'\\xb4\\xd82\\xbe\\xecP\\xd1=6\\xd7\\x00\\xbej-l>\\x16\\x83S\\xbep\\xdfE=X\\xe4M=\\xa8^\\xa0=\\x96\\xa5O\\xbe\\x10\\x83h=0\\x05\\xcc<`8 =\\xb0(\\xc8\\xbd\\x1a\\x1dT\\xbe\\xb8\\x92O\\xbe\\x08\\xabD=',\n",
       "                 'dims': [1, 1, 4, 4],\n",
       "                 'data_type': FLOAT},\n",
       "                'bias': {}},\n",
       "               'attributes': None,\n",
       "               'data_layout': None,\n",
       "               'inputs': [0],\n",
       "               'outputs': [2]})])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('torchinfer-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bd0c8d0c26ca6671a08d77814ef617b240994f0023ad3748be1965a15688631"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
